{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gamma, beta, uniform\n",
    "\n",
    "from scipy.stats import gamma, beta\n",
    "import talib\n",
    "from tqdm.notebook import tqdm\n",
    "from functools import partial\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "\n",
    "from macro_models import gaussian_process, batched_gaussian_process\n",
    "from micro_models import simple_batch_diffusion\n",
    "from helpers import build_distance_matrix\n",
    "from priors import diffusion_prior, length_scale_prior, diffusion_prior_gp\n",
    "from transformations import scale_z, unscale_z\n",
    "from networks_10092022 import DynamicGaussianNetworkJoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56883ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu setting and checking\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195e86fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SIM = 100\n",
    "N_OBS = 100\n",
    "N_SAMPLES = 4000\n",
    "N_PARAMS = 3\n",
    "\n",
    "PARAM_LABELS = ['Drift rate 1', 'Threshold', 'Non-decision time']\n",
    "PARAM_NAMES = [r'$v_1$', r'$a$', r'$\\tau$']\n",
    "\n",
    "MACRO_MEAN = uniform(0.1, 10.).mean()\n",
    "MACRO_STD = uniform(0.1, 10.).std()\n",
    "MICRO_MEANS = [1.4, 1.6, 0.55] # calculated based on many simulated theta_t [1.3, 1.5, 0.5]\n",
    "MICRO_STDS = [1.3, 1.2, 0.4] # calculated based on many simulated theta_t [0.87, 0.48, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2bf6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load simulated data and true params\n",
    "sim = pd.read_pickle('../../data/sim_data/static_dm_data_100.pkl')\n",
    "x_nn = sim['rt']\n",
    "micro_true = sim['theta']\n",
    "x_nn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f002e0d",
   "metadata": {},
   "source": [
    "## Prepare dynamic stan posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f9c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    '''\n",
    "    alist.sort(key=natural_keys) sorts in human order\n",
    "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
    "    (See Toothy's implementation in the comments)\n",
    "    '''\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0bc041",
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = \"C:/Users/Lukas.Schumacher/Documents/GitHub/dynamic_dm/benchmarks/stan/dynamic_stan_fits\"\n",
    "files = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "files.sort(key=natural_keys)\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2bd482",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_stan_post = np.empty((N_SIM, N_OBS, N_SAMPLES, N_PARAMS))\n",
    "for i in range(len(files)):\n",
    "    post_samples = pd.read_csv('dynamic_stan_fits/' + files[i], index_col=False)\n",
    "    dynamic_stan_post[i] = post_samples.to_numpy()[:, 3:].reshape(100, 4000, 3)\n",
    "\n",
    "dynamic_stan_post.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937b60b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and std of posterior stds\n",
    "dynamic_stan_post_std_means = dynamic_stan_post.std(axis=2).mean(axis=0)\n",
    "dynamic_stan_post_std_stds = dynamic_stan_post.std(axis=2).std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b50c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get posterior means\n",
    "dynamic_stan_post_means = dynamic_stan_post.mean(axis=2)\n",
    "dynamic_stan_post_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507726e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_stan_abs_error = np.empty((N_SIM, N_OBS, N_PARAMS))\n",
    "for i in range(N_SIM):\n",
    "    dynamic_stan_abs_error[i] = np.abs(dynamic_stan_post_means[i] - micro_true[i])\n",
    "dynamic_stan_abs_error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef6e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_stan_abs_error_mean = dynamic_stan_abs_error.mean(axis=0)\n",
    "dynamic_stan_abs_error_std = dynamic_stan_abs_error.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca5c919",
   "metadata": {},
   "source": [
    "## Neural Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa1ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_fun(batch_size, T):\n",
    "    dist_mat = build_distance_matrix(T)\n",
    "    theta0 = diffusion_prior_gp(batch_size, n_cond=1)\n",
    "    eta = length_scale_prior(batch_size, 3)\n",
    "\n",
    "    theta_t = batched_gaussian_process(theta0, dist_mat, eta, amplitudes=[0.25, 0.25, 0.15])\n",
    "    rt = simple_batch_diffusion(theta_t).astype(np.float32)\n",
    "\n",
    "    # standardize parameters\n",
    "    eta_z = scale_z(eta, MACRO_MEAN, MACRO_STD)\n",
    "    theta_t_z = scale_z(theta_t, MICRO_MEANS, MICRO_STDS)\n",
    "\n",
    "    return eta_z.astype(np.float32), theta_t_z.astype(np.float32), rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50602018",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "eta_z, theta_t_z, rt = generator_fun(N_SIM, N_OBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f37e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(y_true, y_pred):\n",
    "    return tf.reduce_mean(-y_pred.log_prob(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5561e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_trainer(generator, network, optimizer, steps_per_epoch, p_bar):\n",
    "    losses = []\n",
    "    for step in range(1, steps_per_epoch+1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            # Simulate from model\n",
    "            macro_params, micro_params, data = generator() \n",
    "\n",
    "            # Forward pass\n",
    "            posterior = network(data)\n",
    "\n",
    "            # loss computation\n",
    "            T = int(micro_params.shape[1])\n",
    "            loss = nll(tf.concat([tf.stack([macro_params] * T, axis=1), micro_params], axis=-1), posterior)\n",
    "        \n",
    "        # One step backprop\n",
    "        g = tape.gradient(loss, network.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(g, network.trainable_variables))\n",
    "        losses.append(loss.numpy())\n",
    "\n",
    "        # Update progress bar\n",
    "        p_bar.set_postfix_str(\"Ep: {},Step {},Loss: {:.3f},Loss.Avg: {:.3f}\"\n",
    "                              .format(ep, step, loss.numpy(), np.mean(losses)))\n",
    "        p_bar.update(1)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33dc543",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 100\n",
    "batch_size = 16\n",
    "simulator = partial(generator_fun, T=T, batch_size=batch_size)\n",
    "epochs = 100\n",
    "steps_per_epoch = 1000\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.001,\n",
    "    decay_steps=5000,\n",
    "    decay_rate=0.8,\n",
    "    staircase=True\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8238f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_settings = {\n",
    "    'embedding_lstm_units' : 512, \n",
    "    'embedding_gru_units': 512,\n",
    "    'embedding_dense_args': dict(units=256, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    'posterior_dense_args': dict(units=128, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    'n_micro_params': 3,\n",
    "    'n_macro_params': 3\n",
    "}\n",
    "network = DynamicGaussianNetworkJoint(network_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ff019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses = []\n",
    "# for ep in range(1, epochs+1):\n",
    "#     with tqdm(total=steps_per_epoch, desc='Training epoch {}'.format(ep)) as p_bar:\n",
    "#         losses_ep = epoch_trainer(simulator, network, optimizer, steps_per_epoch, p_bar)\n",
    "#         losses.append(losses_ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa238d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network.save_weights('trained_networks/1_drift_100_gpddm_joint_23Sept')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daef4cb",
   "metadata": {},
   "source": [
    "## Fit Gaussian Procces DDM to Static Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedd6f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.save_weights('trained_networks/1_drift_100_gpddm_joint_23Sept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f38b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "post_eta_z, post_theta_t_z = network.sample_n(x_nn, N_SAMPLES)\n",
    "post_theta_t_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727a050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_eta = unscale_z(post_eta_z, MACRO_MEAN, MACRO_STD).numpy()\n",
    "post_theta_t = unscale_z(post_theta_t_z, MICRO_MEANS, MICRO_STDS).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5088ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and sd posterior sd's from dynamic model fits\n",
    "neural_post_std_means = post_theta_t.std(axis=0).mean(axis=0)\n",
    "neural_post_std_stds = post_theta_t.std(axis=0).std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fb4352",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_post_means = post_theta_t.mean(axis=0)\n",
    "neural_post_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd229962",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_abs_error = np.empty((N_SIM, N_OBS, N_PARAMS))\n",
    "for i in range(N_SIM):\n",
    "    neural_abs_error[i] = np.abs(neural_post_means[i] - micro_true[i])\n",
    "\n",
    "neural_abs_error_mean = np.mean(neural_abs_error, axis=0)\n",
    "neural_stan_abs_error_std = np.std(neural_abs_error, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5adffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_labels = ['Drift rate', 'Threshold', 'Non-decision time']\n",
    "param_names = [r'$v$', r'$a$', r'$\\tau$']\n",
    "font_size_large = 32\n",
    "font_size_small = 26\n",
    "time = np.arange(dynamic_stan_post_std_stds.shape[0])\n",
    "ALPHA = 0.6\n",
    "f, axarr = plt.subplots(2, 3, figsize=(20, 10))\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    if i < 3:\n",
    "        # plot neural results\n",
    "        ax.plot(time, neural_abs_error_mean[:, i], alpha=0.9, color='#852626')\n",
    "        ax.fill_between(time, neural_abs_error_mean[:, i] - neural_stan_abs_error_std[:, i]/2, neural_abs_error_mean[:, i] + neural_stan_abs_error_std[:, i]/2,\n",
    "                        alpha=ALPHA, label='Neural Dynamic DM', color='#852626')\n",
    "\n",
    "        # plot dynamic stan\n",
    "        ax.plot(time, dynamic_stan_abs_error_mean[:, i], alpha=0.9, color='#598f70')\n",
    "        ax.fill_between(time, dynamic_stan_abs_error_mean[:, i] - dynamic_stan_abs_error_std[:, i]/2, dynamic_stan_abs_error_mean[:, i] + dynamic_stan_abs_error_std[:, i]/2,\n",
    "                        alpha=ALPHA, label='Stan Dynamic DM', color='#598f70')\n",
    "\n",
    "        ax.set_title(param_labels[i] + ' ({})'.format(param_names[i]), fontsize=font_size_large)\n",
    "\n",
    "        if i == 0:\n",
    "            ax.set_xlabel('Trial', fontsize=font_size_large)\n",
    "            ax.set_ylabel(r'MAE $(\\bar{\\theta} - \\theta^*)$', fontsize=font_size_large)\n",
    "        if i == 2:\n",
    "            ax.legend(fontsize=font_size_small, loc='best', fancybox=False, shadow=False)\n",
    "\n",
    "    else:\n",
    "        # plot neural results\n",
    "        ax.plot(time, neural_post_std_means[:, i-3], alpha=0.9, color='#852626')\n",
    "        ax.fill_between(time, neural_post_std_means[:, i-3]+neural_post_std_stds[:, i-3]/2, neural_post_std_means[:, i-3]-neural_post_std_stds[:, i-3]/2,\n",
    "                        alpha=ALPHA, label='Neural Dynamic DM', color='#852626')\n",
    "\n",
    "        # plot dynamic stan\n",
    "        ax.plot(time, dynamic_stan_post_std_means[:, i-3], alpha=0.9, color='#598f70')\n",
    "        ax.fill_between(time, dynamic_stan_post_std_means[:, i-3]+dynamic_stan_post_std_stds[:, i-3]/2, dynamic_stan_post_std_means[:, i-3]-dynamic_stan_post_std_stds[:, i-3]/2,\n",
    "                        alpha=ALPHA, label='Stan Dynamic DM', color='#598f70')\n",
    "        \n",
    "        \n",
    "        if i == 3:\n",
    "            ax.set_xlabel('Trial', fontsize=font_size_large)\n",
    "            ax.set_ylabel('Post. std. deviation', fontsize=font_size_large)\n",
    "\n",
    "    if i == 0 or i == 3:\n",
    "        ax.set_yticks([0.0, 0.2, 0.4, 0.6, 0.8])\n",
    "    elif i == 1 or i == 4:\n",
    "        ax.set_yticks([0.0, 0.2, 0.4, 0.6])\n",
    "    else:\n",
    "        ax.set_yticks([0.0, 0.1, 0.2])\n",
    "\n",
    "    ax.set_xticks([1, 25, 50, 75, 100])\n",
    "    ax.tick_params(axis='both', which='major', labelsize=28, length=8)\n",
    "    # ax.grid(alpha=0.3)\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../plots/plot_stan_benchmark_joint.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "3e3407267051e534a6de4f0523cb42ed5b5ed38d4238d1097c3ce82aa60caaae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
