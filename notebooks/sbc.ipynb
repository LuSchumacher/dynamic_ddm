{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essentials\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from scipy.stats import gamma, beta\n",
    "\n",
    "# bayesflow\n",
    "sys.path.append(os.path.abspath(os.path.join('../../BayesFlow')))\n",
    "from bayesflow.diagnostics import plot_sbc_ecdf, plot_sbc_histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../src\")\n",
    "from networks_10092022 import DynamicGaussianNetworkJoint\n",
    "from priors import diffusion_prior, random_walk_prior\n",
    "from micro_models import dynamic_batch_diffusion, diffusion_trial, fast_dm_simulate\n",
    "from macro_models import random_walk_shared_var, random_walk\n",
    "from context import generate_design_matrix\n",
    "from transformations import scale_z, unscale_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post_samples      : np.ndarray of shape (n_data_sets, n_post_draws, n_params)\n",
    "#                     The posterior draws obtained from n_data_sets\n",
    "\n",
    "# prior_samples     : np.ndarray of shape (n_data_sets, n_params)\n",
    "#                     The prior draws obtained for generating n_data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OBS         = 3200\n",
    "N_PARAMS      = 6\n",
    "N_SBC         = 2000\n",
    "N_SAMPLES_SBC = 100\n",
    "\n",
    "TIME_SLICES = np.array([1, 800, 1600, 2400, 3200]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACRO_MEAN  = beta(a=1, b=25).mean()\n",
    "MACRO_STD   = beta(a=1, b=25).std()\n",
    "MICRO_MEANS = [1.75, 1.75, 1.75, 1.75, 1.7, 1] # calculated based on 10000 simulated theta_1:3200\n",
    "MICRO_STDS   = [1.5, 1.5, 1.5, 1.5, 1.25, 1] # calculated based on 10000 simulated theta_1:3200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_fun(batch_size, T):\n",
    "    theta = diffusion_prior(batch_size, n_cond=N_PARAMS-2)\n",
    "    eta = random_walk_prior(batch_size, N_PARAMS)\n",
    "    theta_t = random_walk(theta, eta, T)\n",
    "    context = generate_design_matrix(batch_size, T)\n",
    "    rt = dynamic_batch_diffusion(theta_t, context).astype(np.float32)\n",
    "    x = tf.concat((rt, to_categorical(context[:, :, np.newaxis])), axis=-1)\n",
    "\n",
    "    eta_z = scale_z(eta, MACRO_MEAN, MACRO_STD)\n",
    "    \n",
    "    theta_t_z = theta_t.copy()\n",
    "    for i in range(theta_t.shape[0]):\n",
    "        theta_t_z[i] =  scale_z(theta_t[i], MICRO_MEANS,  MICRO_STDS)\n",
    "\n",
    "    return eta_z.astype(np.float32), theta_t_z.astype(np.float32), x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_settings = {\n",
    "    'embedding_lstm_units' : 512, \n",
    "    'embedding_gru_units': 512,\n",
    "    'embedding_dense_args': dict(units=256, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    'posterior_dense_args': dict(units=128, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    'n_micro_params': 6,\n",
    "    'n_macro_params': 6\n",
    "}\n",
    "network = DynamicGaussianNetworkJoint(network_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.load_weights('../trained_networks/full_dynamic_dm_3200_joint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# generate data\n",
    "eta_z, theta_t_z, data = generator_fun(N_SBC, N_OBS)\n",
    "print(eta_z.shape)\n",
    "print(theta_t_z.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# eta_z_pred, theta_z_pred = tf.concat([network.sample_n(x, N_SAMPLES_SBC)\n",
    "#                          for x in tf.split(data, 10, axis=0)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for x in tf.split(data, 250, axis=0):\n",
    "    if counter == 0:\n",
    "        eta_z_pred, theta_z_pred = network.sample_n(x, N_SAMPLES_SBC)\n",
    "    else:\n",
    "        eta_z_tmp, theta_z_tmp = network.sample_n(x, N_SAMPLES_SBC)\n",
    "        eta_z_pred = np.concatenate((eta_z_pred, eta_z_tmp), axis=1)\n",
    "        theta_z_pred = np.concatenate((theta_z_pred, theta_z_tmp), axis=1)\n",
    "    counter += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_pred = unscale_z(theta_z_pred, MICRO_MEANS, MICRO_STDS)\n",
    "theta_sim = unscale_z(theta_t_z, MICRO_MEANS, MICRO_STDS)\n",
    "theta_pred = np.transpose(theta_pred, (1, 0, 2, 3))\n",
    "print(theta_pred.shape)\n",
    "print(theta_sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post_samples      : np.ndarray of shape (n_data_sets, n_post_draws, n_params)\n",
    "#                     The posterior draws obtained from n_data_sets\n",
    "\n",
    "# prior_samples     : np.ndarray of shape (n_data_sets, n_params)\n",
    "#                     The prior draws obtained for generating n_data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_SLICES = np.array([1, 800, 1600, 2400, 3200]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in TIME_SLICES:\n",
    "    plot_sbc_ecdf(theta_pred[:, :, i, :], theta_sim[:, i, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in TIME_SLICES:\n",
    "    plot_sbc_histograms(theta_pred[:, :, i, :], theta_sim[:, i, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "c85bf36f462aee8672315966a66dd5e91fa71003ac562e7969aa481cd7b291c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
