{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb2123c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from helpers import build_distance_matrix\n",
    "from macro_models import batched_gaussian_process\n",
    "from priors import diffusion_prior_gp, length_scale_prior\n",
    "from micro_models import dynamic_batch_diffusion\n",
    "from networks_10092022 import DynamicGaussianNetworkJoint\n",
    "from context import generate_design_matrix\n",
    "from transformations import unscale_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff59072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GRU, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2e003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56cc9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daea8de",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da66e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 3200\n",
    "DIST_MAT = build_distance_matrix(T)\n",
    "AMPLITUDES = [0.25, 0.25, 0.25, 0.25, 0.25, 0.15]\n",
    "BATCH_SIZE = 16\n",
    "TEST_SIZE = 10\n",
    "N_CHUNKS = 4000\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd127b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS_MEAN = [10.0, 10.0, 10.0, 10.0, 10.0, 10.0,\n",
    "               1.6, 1.6, 1.6, 1.6, 1.6, 0.5]\n",
    "PARAMS_STD = [5.7, 5.7, 5.7, 5.7, 5.7 , 5.7,\n",
    "              1.75, 1.75, 1.75, 1.75, 1.75, 0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88e3755",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d74fde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_fun(batch_size):\n",
    "    theta0 = diffusion_prior_gp(batch_size, n_cond=4)\n",
    "    eta = length_scale_prior(batch_size, 6)\n",
    "    eta_t = np.stack([eta] * T, axis=1)\n",
    "    theta_t = batched_gaussian_process(theta0, DIST_MAT, eta, amplitudes=AMPLITUDES)\n",
    "    context = generate_design_matrix(batch_size, T)\n",
    "    rt = dynamic_batch_diffusion(theta_t, context)\n",
    "    x = np.concatenate((rt, to_categorical(context[:, :, np.newaxis])), axis=-1)\n",
    "\n",
    "    params_t = np.concatenate([eta_t, theta_t], axis=-1)\n",
    "    params_t_z = (params_t - PARAMS_MEAN) / PARAMS_STD\n",
    "    \n",
    "    return params_t_z.astype(np.float32), x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62134bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def presimulate_data():\n",
    "    for n in range(N_CHUNKS):\n",
    "        params_t_z, x = generator_fun(BATCH_SIZE)\n",
    "        np.save(f'../data/offline_data/data/x_{n}.npy', x)\n",
    "        np.save(f'../data/offline_data/parameters/parameters_{n}.npy', params_t_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30afcabe-6c51-46cc-ac15-24469c93348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# presimulate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dc17cb-73a8-4d15-9f59-7616787d51f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkLoader:\n",
    "    def __init__(self, path_to_data):\n",
    "        self.path_to_data = path_to_data\n",
    "        self.data_list = sorted(os.listdir(os.path.join(path_to_data, 'data')), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        self.params_list = sorted(os.listdir(os.path.join(path_to_data, 'parameters')), key=lambda f: int(re.sub('\\D', '', f)))\n",
    "        self.indices = list(range(len(self.data_list)))\n",
    "        np.random.shuffle(self.indices)\n",
    "        self.num_batches = len(self.data_list)\n",
    "        self.current_index = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.current_index < self.num_batches:\n",
    "            self.current_index += 1\n",
    "            idx = self.indices[self.current_index -1]\n",
    "            batch_x = np.load(os.path.join(self.path_to_data, 'data', self.data_list[idx]))\n",
    "            batch_params = np.load(os.path.join(self.path_to_data, 'parameters', self.params_list[idx]))\n",
    "            return batch_params, batch_x\n",
    "        self.indices = list(range(len(self.data_list)))\n",
    "        np.random.shuffle(self.indices)\n",
    "        self.current_index = 0\n",
    "        raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00405b96-ecee-472f-940e-1f8601165190",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ChunkLoader('../data/offline_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec913f3-1d00-468e-831e-981212e78c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Sequential([\n",
    "    GRU(128, return_sequences=True),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dense(128, activation='elu'),\n",
    "    Dense(tfpl.IndependentNormal.params_size(12)),\n",
    "    tfpl.IndependentNormal(12)\n",
    "])\n",
    "steps_per_epoch = 500\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.0005,\n",
    "    decay_steps=2500,\n",
    "    decay_rate=0.8,\n",
    "    staircase=True\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35d3dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(y_true, y_pred):\n",
    "    return tf.reduce_mean(-y_pred.log_prob(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0053f8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_trainer(generator, network, optimizer, steps_per_epoch, p_bar):\n",
    "    losses = []\n",
    "    for step, batch in enumerate(generator):\n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            # Simulate from model\n",
    "            params_t_z, data = batch\n",
    "\n",
    "            # Forward pass\n",
    "            posterior = network(data)\n",
    "\n",
    "            # loss computation\n",
    "            loss = nll(params_t_z, posterior)\n",
    "        \n",
    "        # One step backprop\n",
    "        g = tape.gradient(loss, network.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(g, network.trainable_variables))\n",
    "        losses.append(loss.numpy())\n",
    "\n",
    "        # Update progress bar\n",
    "        p_bar.set_postfix_str(\"Ep: {},Step {},Loss: {:.3f},Loss.Avg: {:.3f}\"\n",
    "                              .format(ep, step, loss.numpy(), np.mean(losses)))\n",
    "        p_bar.update(1)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f091e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_epoch(network, optimizer, dataset, batch_size, p_bar, mmd_weight=0.1):\n",
    "#     \"\"\" Helper function for one simulation epoch. \"\"\"\n",
    "    \n",
    "#     losses = []\n",
    "#     for bi, (data, params) in enumerate(dataset):\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             params_pred = network(data)\n",
    "#             params_z = (params - params_mean) / params_std\n",
    "#             loss = nll(params_z, params_pred)\n",
    "            \n",
    "#         # Backprop step\n",
    "#         g = tape.gradient(loss, network.trainable_variables)\n",
    "#         optimizer.apply_gradients(zip(g, network.trainable_variables))\n",
    "#         losses.append(loss.numpy())\n",
    "\n",
    "#         # Update progress bar\n",
    "#         p_bar.set_postfix_str(\"Batch {},Loss: {:.3f},Avg.Loss: {:.3f}\"\n",
    "#                               .format(bi+1, loss.numpy() , np.mean(losses)))\n",
    "#         p_bar.update(1)\n",
    "#     return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6357f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    with tqdm(total=loader.num_batches, desc=f'Training Epoch {ep}') as p_bar:\n",
    "        loss_ep = epoch_trainer(loader, network, optimizer, steps_per_epoch, p_bar)\n",
    "        losses.append(loss_ep)\n",
    "    network.save_weights('../trained_networks/gp_ddm_3200_joint')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58775c2a",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6cf8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network.load_weights('../trained_networks/gp_ddm_3200_joint')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8752bff6",
   "metadata": {},
   "source": [
    "## Gen Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09bbbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta0 = diffusion_prior_gp(TEST_SIZE, n_cond=1)\n",
    "# eta = length_scale_prior(TEST_SIZE, 3)\n",
    "# theta_test = batched_gaussian_process(theta0, DIST_MAT, eta, amplitudes=AMPLITUDES)\n",
    "# rt_test = simple_batch_diffusion(theta_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d92137",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_test, x_test = generator_fun(TEST_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950943b2",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee4caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = network(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a4591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_means = preds.mean()[:, :, 6:] \n",
    "theta_stds = preds.stddev()[:, :, 6:]\n",
    "theta_test = params_test[:, :, 6:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa6da58",
   "metadata": {},
   "source": [
    "##  Visualize Predictions Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4790dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(TEST_SIZE, 6, figsize=(25, 30))\n",
    "std_mul = 2\n",
    "time = np.arange(1, theta_test.shape[1]+1)\n",
    "for j in range(TEST_SIZE):\n",
    "    for i in range(6):\n",
    "        ax = axarr[j, i]\n",
    "        ax.plot(time, theta_test[j, :, i], label='True', color='black', linestyle='dashed')\n",
    "        # ax.plot(time, theta_means[j, :, i], label='Pred', lw=2, color='#8c6eb5')\n",
    "        # ax.fill_between(time, \n",
    "        #                 theta_means[j, :, i] + std_mul * theta_stds[j, :, i], \n",
    "        #                 theta_means[j, :, i] - std_mul * theta_stds[j, :, i], color='#8c6eb5', alpha=0.3)\n",
    "        sns.despine(ax=ax)\n",
    "        ax.legend()\n",
    "        ax.grid(alpha=0.3)\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a712ddd",
   "metadata": {},
   "source": [
    "## Visualize Slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b6aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_SIZE = 300\n",
    "theta0 = diffusion_prior_gp(VAL_SIZE, n_cond=1)\n",
    "eta = length_scale_prior(VAL_SIZE, 3)\n",
    "theta_test = batched_gaussian_process(theta0, DIST_MAT, eta, amplitudes=AMPLITUDES)\n",
    "rt_test = simple_batch_diffusion(theta_test).astype(np.float32)\n",
    "SLICE_POINTS = [2, 50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6fbb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_preds = network(rt_test)\n",
    "theta_means = theta_preds.mean().numpy() * PARAMS_STD + PARAMS_MEAN\n",
    "theta_stds = theta_preds.stddev().numpy() * PARAMS_STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0267ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(len(SLICE_POINTS), 3, figsize=(10, 10))\n",
    "for j in range(len(SLICE_POINTS)):\n",
    "    for i in range(3):\n",
    "        ax = axarr[j, i]\n",
    "        true = theta_test[:, SLICE_POINTS[j]-1, i]\n",
    "        pred = theta_means[:, SLICE_POINTS[j]-1, i]\n",
    "        std = theta_stds[:, SLICE_POINTS[j]-1, i]\n",
    "        ax.errorbar(true, pred, yerr=std, fmt='o', alpha=0.5, color='#8c6eb5')\n",
    "        # ax.scatter(true, pred, color='#8c6eb5')\n",
    "        sns.despine(ax=ax)\n",
    "        ax.grid(alpha=0.3)\n",
    "        \n",
    "        lower = min(true.min(), pred.min())\n",
    "        upper = max(true.max(), pred.max())\n",
    "        eps = (upper - lower) * 0.1\n",
    "        ax.set_xlim([lower - eps, upper + eps])\n",
    "        ax.set_ylim([lower - eps, upper + eps]) \n",
    "        ax.plot([ax.get_xlim()[0], ax.get_xlim()[1]], [ax.get_ylim()[0], ax.get_ylim()[1]], \n",
    "                 color='black', alpha=0.9, linestyle='dashed')\n",
    "        ax.set_xlabel('True')\n",
    "        ax.set_ylabel('Estimated mean')\n",
    "        if i == 0:\n",
    "            ax.text(-0.5, 0.5, f'T={SLICE_POINTS[j]}',\n",
    "            horizontalalignment='left',\n",
    "            verticalalignment='center',\n",
    "            transform=ax.transAxes)\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1f5800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c85bf36f462aee8672315966a66dd5e91fa71003ac562e7969aa481cd7b291c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
